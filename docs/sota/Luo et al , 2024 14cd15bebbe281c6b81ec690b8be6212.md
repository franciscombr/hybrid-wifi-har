# Luo et al., 2024

Title: Vision Transformers for Human Activity Recognition Using WiFi Channel State Information
Year: 2024
Status: Skimmed
Type: Method
Tags: Computer architecture, Deep learning, Human activity recognition (HAR), Transformers, WiFi channel state information (CSI), WiFi sensing, Wireless fidelity, feature extraction, human activity recognition, sensors, vision transformer (ViT)
Last edited: November 29, 2024 11:32 AM
Abstract: Wireless sensing and communication evolved separately in the past. However, integrated sensing and communication (ISAC) unlocks a new era of mobile network capabilities, with WiFi emerging as a prime candidate. By leveraging existing WiFi infrastructure and frequencies, ISAC enables powerful services like accurate localization and human activity recognition (HAR). WiFi-based HAR is a prime example powered by the magic of ISAC. WiFi channel state information (CSI) is susceptible to human movement disturbances; the alterations in CSI mirror the dynamic attributes of human activities. Given the intricate relationship between human activities and CSI, numerous deep learning models have been introduced to enhance HAR accuracy. Recently, transformer-based models have achieved excellent performance in various tasks, including speech recognition, natural language processing, and image classification. This has spurred research into incorporating transformer-based models into WiFi sensing applications. However, their application in WiFi-based HAR remains nascent. Vision transformer (ViT) is well-suited for analyzing WiFi CSI signals in the form of spectra, such as the Doppler frequency spectrum frequently utilized in related studies, owing to its data structure mimicking that of images. In this study, we explored five widely used ViT architectures (vanilla ViT, SimpleViT, DeepViT, SwinTransformer, and CaiT) for WiFi CSI-based HAR using two publicly available data sets, UT-HAR and NTU-Fi HAR. Our work aims to assess and compare the performance of diverse ViT architectures for WiFi CSI-based HAR and provide guidelines for WiFi-based HAR modeling and ViT selection, considering accuracy, model size, and computational efficiency.
Item Type: Journal Article
Authors: Luo, Fei
Khan, Salabat
Jiang, Bin
Wu, Kaishun
URL: https://ieeexplore.ieee.org/document/10477406
Project: ML

### Overview

- Objective
    - To evaluate and compare the performance of five vision transformer (ViT) architectures for human activity recognition (HAR) using WiFi Channel State Information (CSI), providing insights into their accuracy, computational efficiency, and model size.
- Key Contributions
    - First comprehensive comparison of different ViT architectures for WiFi CSI-based HAR.
    - Investigated five ViT variants: Vanilla ViT, SimpleViT, DeepViT, SwinTransformer, and CaiT.
    - Demonstrated the efficacy of CaiT for achieving state-of-the-art (SOTA) performance on the UT-HAR dataset while balancing accuracy, computational efficiency, and model size.
- Keywords
    - Human Activity Recognition (HAR)
    - WiFi Channel State Information (CSI)
    - Vision Transformers (ViT)
    - Deep Learning
    - Computational Efficiency

### Methods

- **Approach/Architecture:**
    - Converted WiFi CSI data into spectrograms or raw sequences as inputs for transformers.
    - Evaluated five transformer architectures:
        - **Vanilla ViT**: Standard transformer using self-attention.
        - **SimpleViT**: Modified ViT with optimizations like global average pooling and Mixup augmentation.
        - **DeepViT**: Introduced re-attention mechanisms for improved attention diversity.
        - **SwinTransformer**: Employed shifted windows for localized attention.
        - **CaiT**: Focused on hierarchical class attention for improved patch-to-class embedding.
- **Dataset(s):**
    - UT-HAR Dataset:
        - Activities: Seven (e.g., Lie Down, Sit Down, Walk).
        - Participants: Six individuals, 20 trials per activity.
        - Data Collected: CSI spectrograms using Intel 5300 NIC.
        - Preprocessing: PCA for noise removal, STFT for spectrogram generation.
    - NTU-Fi Dataset:
        - Activities: Six (e.g., Run, Walk, Box, Clean Floor).
        - Participants: 20 individuals across three environments.
        - Data Collected: Raw CSI sequences using Atheros CSI Tool.
- **Techniques Used:**
    - **Feature Extraction:**
        - Spectrograms generated using Short-Time Fourier Transform (STFT).
        - Raw CSI sequence used directly for NTU-Fi dataset.
    - **Transformer Variants:** Applied ViT architectures for classification tasks.

### Results

- **Metrics Reported:**
    - Accuracy
    - Model size (parameters)
    - Computational efficiency (MACs - Multiply-Accumulate Operations)
- **Performance Highlights:**
    - **CaiT:** Best overall performance with 98.78% accuracy on UT-HAR and 98.2% accuracy on NTU-Fi, while maintaining low computational complexity.
    - **DeepViT:** Second-best on UT-HAR but struggled with NTU-Fi due to its reliance on frequency-transformed data.
    - **SimpleViT:** Minor improvements over Vanilla ViT.
    - **SwinTransformer:** Lowest accuracy, highlighting limitations for CSI data compared to image data.
    - CaiT excelled due to its hierarchical class-attention mechanism, enabling efficient information transfer from patches to classes.
- **Comparison to Baselines:**
    - CaiT achieved SOTA results on UT-HAR, outperforming previous works using CNNs and RNNs.
    - Balanced accuracy and computational efficiency compared to DeepViT and SimpleViT.

### Analysis

- **Strengths:**
    - Comprehensive evaluation of multiple ViT architectures for WiFi CSI-based HAR.
    - Demonstrated the applicability of ViTs to non-image data like spectrograms.
    - Highlighted the importance of model efficiency alongside accuracy.
- **Weaknesses/Gaps:**
    - Performance of ViTs like SwinTransformer and DeepViT declined on raw CSI data, suggesting limitations in capturing temporal or frequency features.
    - NTU-Fi dataset analysis lacked preprocessing, which might have contributed to reduced performance.
    - Limited exploration of hybrid ViT models (e.g., combining CNNs with ViTs).
- **Opportunities for Improvement:**
    - Investigate preprocessing techniques for raw CSI data to improve ViT performance.
    - Explore combining ViTs with traditional architectures (e.g., CNNs) to leverage local and global features.
    - Extend evaluations to real-world, multi-user scenarios for broader applicability.

### Relevance to the Project:

- **Insights or Ideas:**
    - CaiTâ€™s hierarchical class-attention approach is a promising technique for improving patch-to-class information transfer in transformer-based HAR systems.
    - Direct application of ViTs to spectrograms validates the potential of leveraging image-inspired techniques for CSI data.
- **Potential for Reuse:**
    - ViT models and hyperparameters can serve as a baseline for your proposed transformer-based HAR system.
    - Datasets (UT-HAR and NTU-Fi) offer diverse benchmarks for evaluating your models.
- **Unanswered Questions:**
    - How do hybrid ViT-CNN models perform compared to standalone ViTs for WiFi CSI data?
    - Can the success of CaiT generalize to other non-image datasets like raw phase or amplitude CSI data?